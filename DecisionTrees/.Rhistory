1+1
CAR <- read.table("/Users/elieharik/Desktop/WORK/NORTHWESTERN/Winter Quarter/MSiA 420 - PA II /Notes/Notes 1 - Cross Val/Code/Data_for_Lecture_Examples/Car.csv", sep = ",", header = TRUE)
str(Car)
str(CAR)
names(CAR)
?glm
glm1 <- glm(y~., family = binomial(link = "logit"), data = CAR)
summary(glm1)
names(glm1)
phat <- predict(glm1, type = "response")
?predict
phat
CAR
data.frame(CAR, phat = round(phat,3))
y <- CAR$y
plot(CAR$car_age[y==1], CAR$income[y==1], col = "red", pch = 15, xlab = "car_age", ylab = "income", xlim = c(1,6), ylim = c(10,100))
points(CAR$car_age[y==0], CAR$income[y==0], col = "black", pch = 19)
MLC <- read.table("/Users/elieharik/Desktop/WORK/NORTHWESTERN/Winter Quarter/MSiA 420 - PA II /Notes/Notes 1 - Cross Val/Code/Data_for_Lecture_Examples/MLC.csv", sep = ",", header = TRUE)
str(MLC)
names(MLC)
x1 <- MLC$Location
x2 <- MLC$Week
y <- MLC$Efficiency
fn <- function(p) {yhat <- p[1] +p[2] * x1 + p[4] * exp(p[3] * x2); sum((y-yhat)^2)}
?nlm
out <- nlm(fn, p=c(1,0,-.5,-.1), hessian = TRUE)
thtea <- out$estimate
library(ISLR)
install.packages("ISLR")
library(ISLR)
set.seed(1)
train=sample(392,196)
?sample
382
392
train
sample(1,100)
sample(101,100)
lm.ft <- lm(mpg ~ horsepower, data = Auto, subset = train)
Auto
Auto[train,]
train
attach(Auto)
names(Auto)
predict(lm.fit, Auto)
predict(lm.ft, Auto)
predict(lm.ft, Auto)[-train]^2
mean(mpg-predict(lm.ft, Auto)[-train]^2)
mean((mpg-predict(lm.ft, Auto))[-train]^2)
lm.fit2 = lm(mpg~poly(horsepower,2), data = Auto, subset = train)
mean((mpg-predict(lm.fit2, Auto))[-train]^2)
install.packages("boot")
library(boot)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
?cv.glm
cv.err <- cv.glm(Auto, glm.fit)
names(cv.err)
cv.err$K
cv.err$delta
set.seed(17)
cv.error.10 = rep(0,10)
rep(0,10)
cv.error.10
#Used to store the CV errors corresponding to the polynomial fits of order one to ten
for i (in 1:10)
for (i in 1:10) {}
for (i in 1:10) {
glm.fit <- glm(mpg~poly(horsepower,i), data = Auto )
cv.error.10[i] <- cv.glm(Auto, glm.fit, K=10)$delta[1]
}
cv.error.10
Portfolio
alpha.fn <- function(data, index) {
X <- data$X[index]
Y <- data$Y[index]
return((var(Y)-cov(X,Y))/(var(X) + var(Y) - 2 * cov(X,Y)))
alpha.fn(Portfolio, 1:100)
}
alpha.fn <- function(data, index) {
X <- data$X[index]
Y <- data$Y[index]
alpha.fn(Portfolio, 1:100)
alpha.fn <- function(data, index) {
X <- data$X[index]
Y <- data$Y[index]
return((var(Y)-cov(X,Y))/(var(X) + var(Y) - 2 * cov(X,Y)))
}
alpha.fn(Portfolio, 1:100)
set.seed(1)
alpha.fn(Portfolio, sample(100,100, replace = T))
sample(100,100, replace = T)
sample(100,1, replace = T)
boot(Portfiolio, alpha.fn, R = 1000)
boot(Portfolio, alpha.fn, R = 1000)
??apply
?view
?view()
??view
library(ISLR)
hitters <- na.omit(Hitters)
plot(hitters$Salary)
hist(hitters$Salary)
hitters$Salary <- log(hitters$Salary)
hist(hitters$Salary)
plot(hitters$Salary)
plot(hitters$Years, hitters$Hits)
setwd("~/Desktop/Dev/Dev/R/Introduction to Statistical Learning/Decision Trees")
library(tree)
install.packages("tree")
#
libarary(ISLR)
library(ISLR)
attach(Carseats)
High = ifelse(Sales<=8, "No", "Yes")
Carseats = data.frame(Carseats, High)
tree.carseats = tree(High~. -Sales, Carseats)
library(tree)
tree.carseats = tree(High~. -Sales, Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats, pretty = 0)
plot(tree.carseats)
text(tree.carseats)
plot(tree.carseats)
#Add that node text
text(tree.carseats, pretty = 0)
?text
plot(tree.carseats)
text(tree.carseats, pretty = 0) #Not sure what that pretty does though
tree.carseats
set.seed(2)
train = sample(1:nrow(Carseats), 200)
Carseats.test = Carseats[-train,]
High.Test = High[-train]
trees.carseats = tree(High~.-Sales, Carseats, subset = train)
tree.pred = predict(tree.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
High.Test = High[-train]
table(tree.pred, High.Test)
set.seed(2)
train = sample(1:nrow(Carseats), 200)
Carseats.test = Carseats[-train,]
High.Test = High[-train]
trees.carseats = tree(High~.-Sales, Carseats, subset = train)
tree.pred = predict(tree.carseats, Carseats.test, type = "class")
table(tree.pred, High.Test)
107 + 77 / 200
(107 + 77) / 200
set.seed (2)
train=sample(1:nrow(Carseats), 200)
Carseats.test=Carseats [-train ,]
High.test=High[-train]
tree.carseats=tree(Highâˆ¼.-Sales,Carseats,subset=train)
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
tree.pred=predict(tree.carseats,Carseats.test,type="class")
table(tree.pred ,High.test)
set.seed(2)
train = sample(1:nrow(Carseats), 200)
Carseats.test = Carseats[-train,]
High.Test = High[-train]
trees.carseats = tree(High~.-Sales, Carseats, subset = train)
tree.pred = predict(tree.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
set.seed (2)
train=sample(1:nrow(Carseats), 200)
Carseats.test=Carseats [-train ,]
High.test=High[-train]
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
tree.pred=predict(tree.carseats,Carseats.test,type="class")
table(tree.pred ,High.test)
set.seed(3)
cv.carseats = cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow = c(1,2))
plot(cv.carseats$size, cv.carseats$dev, type = "B")
plot(cv.carseats$size, cv.carseats$dev, type = "b")
plot(cv.carseats$size, cv.carseats$dev, type = "b")
plot(cv.carseats$k, cv.carseats$dev, type = "b")
prune.carseats = prune.misclass(tree.carseats, best = 9)
plot(prune.carseats)
test(prune.carseats, pretty = 0)
text(prune.carseats, pretty = 0)
tree.pred = predict(prune.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
#0.77
library(MASS)
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston = tree(medv~., Boston, subset = train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston, pretty = 0)
par(mfrow = c(1,1))
plot(tree.boston)
text(tree.boston, pretty = 0)
cv.boston = cv.tree(tree.boston) #Give the function your tree
plot(cv.boston$size, cv.boston$dev, type = "b")
prune.boston = prune.tree(tree.boston, best = 5)
plot(prune.boston)
test(prune.boston, pretty = 0)
text(prune.boston, pretty = 0)
yhat = predict(tree.boston, newData = Boston[-train,])
boston.test = Boston[-train,"medv"]
??medv
plot(yhat, boston.test)
boston.test = Boston[-train] #Look up medv
plot(yhat, boston.test)
boston.test = Boston[-train, ] #Look up medv
plot(yhat, boston.test)
boston.test = Boston[-train, "medv"] #Look up medv
plot(yhat, boston.test)
abline(0,1)
mean((yhat - boston.test)^2)
yhat = predict(tree.boston, newData = Boston[-train,])
boston.test = Boston[-train, "medv"] #Look up medv
plot(yhat, boston.test)
abline(0,1)
mean((yhat - boston.test)^2)
yhat=predict(tree.boston ,newdata=Boston[-train ,])
boston.test=Boston[-train ,"medv"]
plot(yhat,boston.test)
abline (0 ,1)
mean((yhat-boston.test)^2)
yhat = predict(tree.boston, newdata = Boston[-train,])
boston.test = Boston[-train, "medv"] #Look up medv
plot(yhat, boston.test)
abline(0,1)
mean((yhat - boston.test)^2)
